// example call: time webppl model.wppl --require webppl-json --require webppl-sample-writer 1

var chain = last(process.argv)

// data

var data = json.read('../data/data.json');
var tasks = levels(data, "task")
var subjects = levels(data, "id")

var meData = _.filter(data, {
  task: "mutual_exclusivity"})

var meItems = levels(meData, "item")

var infData = _.filter(data, {
  task: "simple_inf"})

var infItems = levels(infData, "item")


// helper functions

var foreach = function(fn, lst) {
  var foreach_ = function(i) {
    if (i < lst.length) {
      fn(lst[i]);
      foreach_(i + 1);
    }
  };
  foreach_(0);
};

var logistic = function(x) {
  1 / (1 + Math.exp(-x))
}

var levels = function(df, label) {
  return _.uniq(_.map(df, label));
}

////////////////////////////////////////
// mutual exclusivity model utilities//

var all_me_objects = [
  { shape: "novel_object"},
  { shape: "familiar_object"}
]

var labels = ["novel_word", "familiar_word"]


var lexicon1 = function(utterance, obj, sem_knowledge) {
  utterance.label == "novel_word" ? obj.shape == "novel_object" :
  utterance.label == "familiar_word" ? flip(sem_knowledge) ?
  obj.shape == "familiar_object" :
  flip() ? obj.shape == "familiar_object" : obj.shape == "novel_object" :
  true
}

var lexicon2 = function(utterance, obj, sem_knowledge) {
  utterance.label == "novel_word" ? obj.shape == "familiar_object" :
  utterance.label == "familiar_word" ? flip(sem_knowledge) ?
  obj.shape == "familiar_object" :
  flip() ? obj.shape == "familiar_object" : obj.shape == "novel_object" :
  true
}

var meLexiconObjects = {
  "novel_word = novel_object": {
    novel_object: "novel_word",
    familiar_object: "familiar_word"
  },
  "novel_word = familiar_object": {
    novel_object: "familiar_word",
    familiar_object: "familiar_word"
  },
}

var meLexiconObject = {
  "novel_word = novel_object": lexicon1,
  "novel_word = familiar_object": lexicon2
}

var meUtterancePrior = function() {
  return uniformDraw([{
    label: "novel_word"
  }, {
    label: "familiar_word"
  }])
}

var meLexiconPrior = Categorical({
  vs: ["novel_word = novel_object", "novel_word = familiar_object"],
  ps: [1, 1]
})

//////////////////////////////////////
// informativeness  model utilities//

var all_objects = [
{ shape: "triangle", id:1, location: 1},
{ shape: "triangle", id:2, location: 2},
{ shape: "circle", id:1, location: 2}
]

// listener prior is over types, not tokens (we use uniformDraw on prior_objects)
var prior_objects = [
{ shape: "triangle", id:1, location: 1},
{ shape: "circle", id:1, location: 2}
]

var labels = ["dax","wug"]

// two possible lexica, corresponding to meaning of words "dax" and "wug"
var lexicon1 = function(utterance, obj){
utterance.label == "dax" ? obj.shape == "triangle" :
utterance.label == "wug" ? obj.shape == "circle" :
true
}

var lexicon2 = function(utterance, obj){
utterance.label == "dax" ? obj.shape == "circle" :
utterance.label == "wug" ? obj.shape == "triangle" :
true
}

var lexiconObjects = {
"dax = triangle": {
triangle: "dax", circle: "wug"
},
"dax = circle": {
triangle: "wug", circle: "dax"
},
}

var lexiconObject = {
"dax = triangle": lexicon1,
"dax = circle" : lexicon2
}

var point = function(utterance, obj){
return obj.location == utterance.point
}


var utterancePrior = function(obj, lexiconName){
  var locationsWithShape = _.map(_.filter(all_objects, {shape: obj.shape}), "location")
  var point = uniformDraw(locationsWithShape)
  var label = lexiconObjects[lexiconName][obj.shape]
  return {label: label, point: point}
}

var LexiconPrior = Categorical({vs: ["dax = triangle","dax = circle" ], ps: [1, 1]})


// setting other parameters

var priorProbs = [.5, .5]

// this is just for now, eventually, we want to substitute this with the by item estimated semantic sem_knowledg

var model = function() {

//////// semantic knowledge /////////////

var globalLineParameters = {
  intercept: uniformDrift({a: -3, b: 3, width: 0.5}),
  slope: uniformDrift({a: 0, b: 2, width: 0.5})
}

var itemVariability = {
  intercept: uniformDrift({a: 0, b: 2, width: 0.2}),
  slope: uniformDrift({a: 0, b: 1, width: 0.2})
}

// conceptually it might not make sense to have two sigmas, but maybe it does
// intercept sigma probably will be smaller than slope sigma
// var item_int_sigma = uniformDrift({a: 0, b: 3, width: 0.2})

var sampleItemParameters = function(itemName) {
  return [itemName, {
      intercept: gaussianDrift({
        mu: globalLineParameters.intercept,
        sigma: itemVariability.intercept,
        width: 0.5
      }),
      slope: gaussianDrift({
        mu: globalLineParameters.slope,
        sigma: itemVariability.slope,
        width: 0.5
      })
    }]
}

// {papaya: {int, slope}, bread: {int, slope}, ... }
var all_item_parameters = _.fromPairs(map(sampleItemParameters, meItems))

// want something that favors smaller values
var subject_sigma = uniformDrift({a: 0, b:1, width: 0.1})

var sampleLinguisticCompetence = function(age){
  return gaussianDrift({ mu: age, sigma: subject_sigma, width: 0.1 })
}

////////////////  speaker optimality ////////////////////////

var globalSpeakerOptimality = {
  mu: sample(Cauchy({location: 1, scale: 2})),
  sigma: uniformDrift({a: 0, b: 1, width: 0.5})
}

var sampleSoParameter = function(id) {
  return [id, {
      speakerOptimality: gaussianDrift({
        mu: globalSpeakerOptimality.mu,
        sigma: globalSpeakerOptimality.sigma,
        width: 0.5
      })
    }]
}

var all_so_parameters = _.fromPairs(map(sampleSoParameter, subjects))

foreach(function(subid){
    var meSubjectData = _.filter(meData, {subid: subid})
    var subj_age = meData[0].age_month
    var subj_linguistic_competence = sampleLinguisticCompetence(subj_age)

// each row is a different item
    foreach(function(row){

      var itemLineParameters = all_item_parameters[row.item]

      var sem_knowledge = logistic(itemLineParameters.intercept +
        itemLineParameters.slope * subj_linguistic_competence)

      var soParameters = all_so_parameters[row.id]

      var speakerOptimality = soParameters.speakerOptimality


        var meLiteralListener = cache(function(utterance){
          Infer({method: "enumerate", model: function(){
            var lexiconName = sample(meLexiconPrior);
            var lexicon = meLexiconObject[melexiconName];
            var obj = sample( Categorical({vs: all_me_objects, ps: [.5,.5]}));
            if ("label" in utterance) {
              var truthValue = lexicon(utterance, obj, sem_knowledge);
              condition(truthValue)
            }
            return obj.shape
          }})}, 10000)

          var meSpeaker = cache(function(obj, meLexiconName){
            Infer({method: "enumerate", model: function(){
              var utterance = utterancePrior();
              var L0 = literalListener(utterance);
              factor(speakerOptimality * L0.score(obj.shape))
              return utterance
            }})}, 10000)

            var mePragmaticListener = function(utterance){
              Infer({method: "enumerate", model: function(){
                // display('inside RSA = ' + sem_knowledge)
                var meLexiconName = sample(meLexiconPrior);
                var obj = sample( Categorical({vs: all_me_objects, ps: [.5,.5]}));
                var S1 = speaker(obj, meLexiconName);
                observe(S1, utterance)
                return obj.shape == "novel_object" ? 1 : 0
              }})}

              var meModelPredictions = mePragmaticListener({label: "novel_word"})

              observe(meModelPredictions, row.correct)

            }, meSubjectData)

          }, subjects)

        foreach(function(subject){
            var soParameters = all_so_parameters[subject]
            query.add(["NA","speaker_optimality", subject], soParameters.speakerOptimality)
         }, subjects)

         foreach(function(item){
           var itemLineParameters = all_item_parameters[item]
           query.add(["mutual_exclusivity","items", item, "intercept", "NA", "NA"], itemLineParameters.intercept)
           query.add(["mutual_exclusivity","items", item, "slope", "NA", "NA"], itemLineParameters.slope)

      }, meItems)

          return query
  }

  var header = "iteration,a,b,c,d,e,f"

  var totalIterations = 10, lag =  1;
  var samples = totalIterations/lag, burn = totalIterations / 2;


  var output_file = 'output/model-' + totalIterations + '_burn' + burn + '_lag' + lag + '_chain' + chain + '.csv'
  var callback = webpplSampleWriter.streamQueryCSV(output_file, header);

  var output = Infer({
    model,
    samples: samples,
    burn: burn,
    lag: lag,
    verbose: true,
    method: 'MCMC',
    onlyMAP: true,
    callbacks: [callback]
  });

  'output written to ' + output_file
